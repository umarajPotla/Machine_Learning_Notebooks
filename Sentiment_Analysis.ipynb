{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "We will implement Naive Bayes classifier to perform sentiment analysis on movie reviews. We will take 1000 positive and 1000 negative reviews and mix them, split them into training and testing dataset. Train the classifier on training dataset and then use it to predict the sentiment on testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk.corpus\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize.moses import MosesDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## opening nltk corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'dolch', 'dolch.zip', 'europarl_raw', 'europarl_raw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'movie_reviews', 'movie_reviews.zip', 'mte_teip5', 'mte_teip5.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nonbreaking_prefixes', 'nonbreaking_prefixes.zip', 'nps_chat', 'nps_chat.zip', 'omw', 'omw.zip', 'opinion_lexicon', 'opinion_lexicon.zip', 'panlex_swadesh.zip', 'paradigms', 'paradigms.zip', 'pil', 'pil.zip', 'pl196x', 'pl196x.zip', 'ppattach', 'ppattach.zip', 'problem_reports', 'problem_reports.zip', 'product_reviews_1', 'product_reviews_1.zip', 'product_reviews_2', 'product_reviews_2.zip', 'propbank.zip', 'pros_cons', 'pros_cons.zip', 'ptb', 'ptb.zip', 'qc', 'qc.zip', 'reuters.zip', 'rte', 'rte.zip', 'semcor.zip', 'senseval', 'senseval.zip', 'sentence_polarity', 'sentence_polarity.zip', 'sentiwordnet', 'sentiwordnet.zip', 'shakespeare', 'shakespeare.zip', 'sinica_treebank', 'sinica_treebank.zip', 'smultron', 'smultron.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'subjectivity', 'subjectivity.zip', 'swadesh', 'swadesh.zip', 'switchboard', 'switchboard.zip', 'timit', 'timit.zip', 'toolbox', 'toolbox.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'unicode_samples', 'unicode_samples.zip', 'universal_treebanks_v20.zip', 'verbnet', 'verbnet.zip', 'webtext', 'webtext.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip', 'ycoe', 'ycoe.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(movie_reviews.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(len(movie_reviews.fileids('pos')))\n",
    "print(\"  \")\n",
    "#print(movie_reviews.fileids('pos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(len(movie_reviews.fileids('neg')))\n",
    "print(\" \")\n",
    "#print(movie_reviews.fileids('pos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "pos_reviews = movie_reviews.fileids('pos')\n",
    "print(len(pos_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "neg_reviews = movie_reviews.fileids('neg')\n",
    "print(len(neg_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['films', 'adapted', 'from', 'comic', 'books', 'have', ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev = nltk.corpus.movie_reviews.words('pos/cv000_29590.txt')\n",
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting tokens back to string for using count Vectorizer and tf-idf calculation\n",
    "- Two ways:\n",
    "    - Use Detokinizer\n",
    "    - Use join method to join all token to form a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detokenizer = MosesDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'films adapted from comic books have had plenty of success, whether they \\'re about superheroes ( batman, superman, spawn), or geared toward kids ( casper) or the arthouse crowd ( ghost world), but there\\' s never really been a comic book like from hell before. for starters, it was created by alan moore ( and eddie campbell), who brought the medium to a whole new level in the mid \\'80s with a 12 - part series called the watchmen. to say moore and campbell thoroughly researched the subject of jack the ripper would be like saying michael jackson is starting to look a little odd. the book ( or \"graphic novel,\" if you will) is over 500 pages long and includes nearly 30 more that consist of nothing but footnotes. in other words, don\\' t dismiss this film because of its source. if you can get past the whole comic book thing, you might find another stumbling block in from hell \\'s directors, albert and allen hughes. getting the hughes brothers to direct this seems almost as ludicrous as casting carrot top in, well, anything, but riddle me this: who better to direct a film that\\' s set in the ghetto and features really violent street crime than the mad geniuses behind menace ii society? the ghetto in question is, of course, whitechapel in 1888 london \\'s east end. it\\' s a filthy, sooty place where the whores ( called \"unfortunates\") are starting to get a little nervous about this mysterious psychopath who has been carving through their profession with surgical precision. when the first stiff turns up, copper peter godley ( robbie coltrane, the world is not enough) calls in inspector frederick abberline ( johnny depp, blow) to crack the case. abberline, a widower, has prophetic dreams he unsuccessfully tries to quell with copious amounts of absinthe and opium. upon arriving in whitechapel, he befriends an unfortunate named mary kelly ( heather graham, say it isn \\'t so) and proceeds to investigate the horribly gruesome crimes that even the police surgeon can\\' t stomach. i don \\'t think anyone needs to be briefed on jack the ripper, so i won\\' t go into the particulars here, other than to say moore and campbell have a unique and interesting theory about both the identity of the killer and the reasons he chooses to slay. in the comic, they don \\'t bother cloaking the identity of the ripper, but screenwriters terry hayes ( vertical limit) and rafael yglesias ( les mis? rables) do a good job of keeping him hidden from viewers until the very end. it\\' s funny to watch the locals blindly point the finger of blame at jews and indians because, after all, an englishman could never be capable of committing such ghastly acts. and from hell \\'s ending had me whistling the stonecutters song from the simpsons for days ( \"who holds back the electric car / who made steve guttenberg a star?\"). don\\' t worry - it \\'ll all make sense when you see it. now onto from hell\\' s appearance: it \\'s certainly dark and bleak enough, and it\\' s surprising to see how much more it looks like a tim burton film than planet of the apes did ( at times, it seems like sleepy hollow 2). the print i saw wasn \\'t completely finished ( both color and music had not been finalized, so no comments about marilyn manson), but cinematographer peter deming ( don\\' t say a word) ably captures the dreariness of victorian - era london and helped make the flashy killing scenes remind me of the crazy flashbacks in twin peaks, even though the violence in the film pales in comparison to that in the black - and - white comic. oscar winner martin childs\\' ( shakespeare in love) production design turns the original prague surroundings into one creepy place. even the acting in from hell is solid, with the dreamy depp turning in a typically strong performance and deftly handling a british accent. ians holm ( joe gould \\'s secret) and richardson ( 102 dalmatians) log in great supporting roles, but the big surprise here is graham. i cringed the first time she opened her mouth, imagining her attempt at an irish accent, but it actually wasn\\' t half bad. the film, however, is all good. 2: 00 - r for strong violence / gore, sexuality, language and drug content'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detokenizer.detokenize(rev, return_str = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rev_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for rev in neg_reviews:\n",
    "    rev_text_neg = rev = nltk.corpus.movie_reviews.words(rev)\n",
    "    review_one_string = \" \".join(rev_text_neg)\n",
    "    review_one_string = review_one_string.replace(\" ,\", \",\")\n",
    "    review_one_string = review_one_string.replace(\" .\", \".\")\n",
    "    review_one_string = review_one_string.replace(\"\\' \", \"'\")\n",
    "    review_one_string = review_one_string.replace(\" \\'\", \"'\")\n",
    "    rev_list.append(review_one_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len(rev_list) \n",
    "print(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for rev in pos_reviews:\n",
    "    rev_text_neg = rev = nltk.corpus.movie_reviews.words(rev)\n",
    "    review_one_string = \" \".join(rev_text_neg)\n",
    "    review_one_string = review_one_string.replace(\" ,\", \",\")\n",
    "    review_one_string = review_one_string.replace(\" .\", \".\")\n",
    "    review_one_string = review_one_string.replace(\"\\' \", \"'\")\n",
    "    review_one_string = review_one_string.replace(\" \\'\", \"'\")\n",
    "    rev_list.append(review_one_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "films adapted from comic books have had plenty of success, whether they're about superheroes ( batman, superman, spawn ), or geared toward kids ( casper ) or the arthouse crowd ( ghost world ), but there's never really been a comic book like from hell before. for starters, it was created by alan moore ( and eddie campbell ), who brought the medium to a whole new level in the mid'80s with a 12 - part series called the watchmen. to say moore and campbell thoroughly researched the subject of jack the ripper would be like saying michael jackson is starting to look a little odd. the book ( or \" graphic novel, \" if you will ) is over 500 pages long and includes nearly 30 more that consist of nothing but footnotes. in other words, don't dismiss this film because of its source. if you can get past the whole comic book thing, you might find another stumbling block in from hell's directors, albert and allen hughes. getting the hughes brothers to direct this seems almost as ludicrous as casting carrot top in, well, anything, but riddle me this : who better to direct a film that's set in the ghetto and features really violent street crime than the mad geniuses behind menace ii society ? the ghetto in question is, of course, whitechapel in 1888 london's east end. it's a filthy, sooty place where the whores ( called \" unfortunates \" ) are starting to get a little nervous about this mysterious psychopath who has been carving through their profession with surgical precision. when the first stiff turns up, copper peter godley ( robbie coltrane, the world is not enough ) calls in inspector frederick abberline ( johnny depp, blow ) to crack the case. abberline, a widower, has prophetic dreams he unsuccessfully tries to quell with copious amounts of absinthe and opium. upon arriving in whitechapel, he befriends an unfortunate named mary kelly ( heather graham, say it isn't so ) and proceeds to investigate the horribly gruesome crimes that even the police surgeon can't stomach. i don't think anyone needs to be briefed on jack the ripper, so i won't go into the particulars here, other than to say moore and campbell have a unique and interesting theory about both the identity of the killer and the reasons he chooses to slay. in the comic, they don't bother cloaking the identity of the ripper, but screenwriters terry hayes ( vertical limit ) and rafael yglesias ( les mis ? rables ) do a good job of keeping him hidden from viewers until the very end. it's funny to watch the locals blindly point the finger of blame at jews and indians because, after all, an englishman could never be capable of committing such ghastly acts. and from hell's ending had me whistling the stonecutters song from the simpsons for days ( \" who holds back the electric car / who made steve guttenberg a star ? \" ). don't worry - it'll all make sense when you see it. now onto from hell's appearance : it's certainly dark and bleak enough, and it's surprising to see how much more it looks like a tim burton film than planet of the apes did ( at times, it seems like sleepy hollow 2 ). the print i saw wasn't completely finished ( both color and music had not been finalized, so no comments about marilyn manson ), but cinematographer peter deming ( don't say a word ) ably captures the dreariness of victorian - era london and helped make the flashy killing scenes remind me of the crazy flashbacks in twin peaks, even though the violence in the film pales in comparison to that in the black - and - white comic. oscar winner martin childs'( shakespeare in love ) production design turns the original prague surroundings into one creepy place. even the acting in from hell is solid, with the dreamy depp turning in a typically strong performance and deftly handling a british accent. ians holm ( joe gould's secret ) and richardson ( 102 dalmatians ) log in great supporting roles, but the big surprise here is graham. i cringed the first time she opened her mouth, imagining her attempt at an irish accent, but it actually wasn't half bad. the film, however, is all good. 2 : 00 - r for strong violence / gore, sexuality, language and drug content\n"
     ]
    }
   ],
   "source": [
    "print(rev_list[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will denote negative reviews with '0' and positive reviews with '1'\n",
    "CReating targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create numpy array with 1000 zeroes as integers\n",
    "neg_targets = np.zeros((1000,), dtype = np.int)\n",
    "#print(neg_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(neg_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_targets = np.ones((1000,), dtype = np.int) \n",
    "#print(pos_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for neg_tar in neg_targets:\n",
    "    target_list.append(neg_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos_tar in pos_targets:\n",
    "    target_list.append(pos_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_list[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create pandas series\n",
    "y = pd.Series(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Count Vectorizer (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(min_df = 2, lowercase = True, stop_words ='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_count_vect = count_vect.fit_transform(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 23784)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_names = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '007',\n",
       " '05',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '100m',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '10th',\n",
       " '11',\n",
       " '110',\n",
       " '113',\n",
       " '115',\n",
       " '11th',\n",
       " '12',\n",
       " '126',\n",
       " '129',\n",
       " '13',\n",
       " '130',\n",
       " '132',\n",
       " '137',\n",
       " '13th',\n",
       " '14',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1500s',\n",
       " '155',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '161',\n",
       " '16mm',\n",
       " '16th',\n",
       " '16x9',\n",
       " '17',\n",
       " '175',\n",
       " '1773',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800s',\n",
       " '1839',\n",
       " '1869',\n",
       " '1871',\n",
       " '1888',\n",
       " '18th',\n",
       " '19',\n",
       " '1900',\n",
       " '1912',\n",
       " '1914',\n",
       " '1919',\n",
       " '1925',\n",
       " '1928',\n",
       " '1930',\n",
       " '1930s',\n",
       " '1932',\n",
       " '1933',\n",
       " '1935',\n",
       " '1937',\n",
       " '1938',\n",
       " '1939',\n",
       " '1940',\n",
       " '1940s',\n",
       " '1941',\n",
       " '1943',\n",
       " '1944',\n",
       " '1945',\n",
       " '1947',\n",
       " '1948',\n",
       " '1949',\n",
       " '1950',\n",
       " '1950s',\n",
       " '1953',\n",
       " '1954',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '1960',\n",
       " '1960s',\n",
       " '1961',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1998s',\n",
       " '1999',\n",
       " '19th',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2013',\n",
       " '2017',\n",
       " '2020',\n",
       " '2029',\n",
       " '2050',\n",
       " '2058',\n",
       " '20s',\n",
       " '20th',\n",
       " '21',\n",
       " '2176',\n",
       " '21st',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '2400',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '25th',\n",
       " '26',\n",
       " '26th',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2d',\n",
       " '2nd',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30th',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '35',\n",
       " '35mm',\n",
       " '36',\n",
       " '360',\n",
       " '37',\n",
       " '39',\n",
       " '3d',\n",
       " '3po',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '40s',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '47',\n",
       " '48',\n",
       " '48th',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '50s',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '571',\n",
       " '58',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '6000',\n",
       " '607',\n",
       " '60s',\n",
       " '61',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '666',\n",
       " '69',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '70mm',\n",
       " '70s',\n",
       " '73',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '80s',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '8mm',\n",
       " '8th',\n",
       " '90',\n",
       " '90210',\n",
       " '90s',\n",
       " '91',\n",
       " '911',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '999',\n",
       " '9mm',\n",
       " '_____',\n",
       " '______',\n",
       " '_and_',\n",
       " '_babe_',\n",
       " '_blade',\n",
       " '_brazil_',\n",
       " '_do_',\n",
       " '_does_',\n",
       " '_don',\n",
       " '_film',\n",
       " '_in',\n",
       " '_is_',\n",
       " '_last_',\n",
       " '_life',\n",
       " '_must_',\n",
       " '_not_',\n",
       " '_real_',\n",
       " '_really_',\n",
       " '_saturday_night_live_',\n",
       " '_saving',\n",
       " '_scream_',\n",
       " '_that_',\n",
       " '_the',\n",
       " '_the_',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaliyah',\n",
       " 'aardman',\n",
       " 'aaron',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandons',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdomen',\n",
       " 'abducted',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'aberration',\n",
       " 'abetted',\n",
       " 'abetting',\n",
       " 'abhorrent',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abo',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abolish',\n",
       " 'abolitionists',\n",
       " 'abominable',\n",
       " 'abomination',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abound',\n",
       " 'abounding',\n",
       " 'abounds',\n",
       " 'abraham',\n",
       " 'abrahams',\n",
       " 'abrams',\n",
       " 'abrasive',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absinthe',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolution',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorption',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abuzz',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abyss',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accentuate',\n",
       " 'accentuates',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accolades',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'accosted',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accounted',\n",
       " 'accounts',\n",
       " 'accumulated',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'acerbic',\n",
       " 'aces',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achiever',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'achingly',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'ack',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acme',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquit',\n",
       " 'acquits',\n",
       " 'acquittal',\n",
       " 'acquitted',\n",
       " 'acres',\n",
       " 'acrimonious',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actioner',\n",
       " 'actioners',\n",
       " 'actionfest',\n",
       " 'actions',\n",
       " 'activated',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actualization',\n",
       " 'actualizing',\n",
       " 'actually',\n",
       " 'acumen',\n",
       " 'acupuncture',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'ad',\n",
       " 'ad2am',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'add',\n",
       " 'addams',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'addled',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'addy',\n",
       " 'ade',\n",
       " 'adefarasin',\n",
       " 'adept',\n",
       " 'adeptly',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adheres',\n",
       " 'adjacent',\n",
       " 'adjani',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjoining',\n",
       " 'adjust',\n",
       " 'adjuster',\n",
       " 'adjusting',\n",
       " 'administration',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admires',\n",
       " 'admiring',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admittance',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admittingly',\n",
       " 'admonition',\n",
       " 'ado',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptive',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adores',\n",
       " 'adorned',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrian',\n",
       " 'adrien',\n",
       " 'adrift',\n",
       " 'adroitly',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventurer',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adversarial',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertiser',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advisable',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advisers',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'aerial',\n",
       " 'aerosmith',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'afar',\n",
       " 'affability',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affectations',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affections',\n",
       " 'affects',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affinity',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'affirming',\n",
       " 'affleck',\n",
       " 'afflicted',\n",
       " 'affliction',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affraid',\n",
       " 'affront',\n",
       " 'afi',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afield',\n",
       " 'afloat',\n",
       " 'afo',\n",
       " 'afoot',\n",
       " 'afore',\n",
       " 'aforementioned',\n",
       " 'aformentioned',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africans',\n",
       " 'afro',\n",
       " 'aftereffects',\n",
       " 'afterglow',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'agape',\n",
       " 'agatha',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'ageing',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggravating',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'agile',\n",
       " 'agility',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agonizingly',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'ah',\n",
       " 'ahabs',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahern',\n",
       " 'ahh',\n",
       " 'ahmed',\n",
       " 'aid',\n",
       " 'aidan',\n",
       " 'aide',\n",
       " 'aided',\n",
       " 'aiding',\n",
       " 'aids',\n",
       " 'aiello',\n",
       " 'ailing',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimee',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'aired',\n",
       " 'aires',\n",
       " 'airline',\n",
       " 'airliner',\n",
       " 'airlock',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airwaves',\n",
       " 'airwolf',\n",
       " 'airy',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'aka',\n",
       " 'aki',\n",
       " 'akin',\n",
       " 'akira',\n",
       " 'akiva',\n",
       " 'akroyd',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'aladdin',\n",
       " 'alain',\n",
       " 'alan',\n",
       " 'alanis',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'albania',\n",
       " 'albanian',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albertson',\n",
       " 'albino',\n",
       " 'albinos',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alcoholics',\n",
       " 'alcoholism',\n",
       " 'alcott',\n",
       " 'alda',\n",
       " 'aldys',\n",
       " 'alec',\n",
       " 'alejandro',\n",
       " 'alek',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alessandro',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandra',\n",
       " 'alexandre',\n",
       " 'alfonso',\n",
       " 'alfre',\n",
       " 'alfred',\n",
       " 'algar',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'aliases',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alida',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienates',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'aliens',\n",
       " 'align',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alison',\n",
       " 'alive',\n",
       " 'allah',\n",
       " 'allan',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allegiances',\n",
       " 'allegory',\n",
       " 'allegra',\n",
       " 'allen',\n",
       " 'allergy',\n",
       " 'alleviate',\n",
       " 'alley',\n",
       " 'alleys',\n",
       " 'alliance',\n",
       " 'alliances',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'alligator',\n",
       " 'alligators',\n",
       " 'allison',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alluded',\n",
       " 'allure',\n",
       " 'alluring',\n",
       " 'allusion',\n",
       " 'allusions',\n",
       " 'ally',\n",
       " 'alma',\n",
       " 'almod',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alright',\n",
       " 'altar',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'alterations',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternates',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alters',\n",
       " 'althea',\n",
       " 'altman',\n",
       " 'altogether',\n",
       " 'altough',\n",
       " 'alum',\n",
       " 'alumni',\n",
       " 'alumnus',\n",
       " 'alvarado',\n",
       " 'alvin',\n",
       " 'alyson',\n",
       " 'alyssa',\n",
       " 'alzheimer',\n",
       " 'amadeus',\n",
       " 'amalgamation',\n",
       " 'amanda',\n",
       " 'amarillo',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurishly',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambassador',\n",
       " 'ambassadors',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'ambient',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambiguously',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambitiously',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'ambrose',\n",
       " 'ambulance',\n",
       " 'ambush',\n",
       " 'amc',\n",
       " 'amen',\n",
       " 'amendment',\n",
       " 'amends',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanized',\n",
       " 'americans',\n",
       " 'americas',\n",
       " 'ames',\n",
       " 'amiable',\n",
       " 'amicable',\n",
       " 'amid',\n",
       " 'amidala',\n",
       " 'amidst',\n",
       " 'amis',\n",
       " 'amish',\n",
       " 'amiss',\n",
       " 'amistad',\n",
       " 'ammo',\n",
       " 'ammunition',\n",
       " 'amnesia',\n",
       " 'amnesiac',\n",
       " 'amok',\n",
       " 'amon',\n",
       " 'amoral',\n",
       " 'amorality',\n",
       " 'amos',\n",
       " 'amounted',\n",
       " 'amounts',\n",
       " 'amphetamines',\n",
       " 'amphibian',\n",
       " 'ample',\n",
       " 'amplified',\n",
       " 'amply',\n",
       " 'amputated',\n",
       " 'amuck',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusements',\n",
       " 'amusing',\n",
       " 'amusingly',\n",
       " 'amy',\n",
       " 'anaconda',\n",
       " 'anacondas',\n",
       " 'anakin',\n",
       " 'anal',\n",
       " 'analogy',\n",
       " 'analyses',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analysts',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'analyzing',\n",
       " 'anand',\n",
       " 'anarchic',\n",
       " 'anarchists',\n",
       " 'anarchy',\n",
       " 'anastasia',\n",
       " 'anatomy',\n",
       " 'ancestors',\n",
       " 'anchor',\n",
       " 'anchors',\n",
       " 'ancient',\n",
       " 'anders',\n",
       " 'anderson',\n",
       " 'andersons',\n",
       " 'andie',\n",
       " 'andre',\n",
       " 'andrea',\n",
       " 'andreas',\n",
       " 'andrew',\n",
       " 'andrews',\n",
       " 'android',\n",
       " 'androids',\n",
       " 'andromeda',\n",
       " 'andrzej',\n",
       " 'andy',\n",
       " 'anecdotal',\n",
       " 'anecdote',\n",
       " 'anecdotes',\n",
       " 'anemic',\n",
       " 'anew',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelic',\n",
       " 'angelina',\n",
       " 'angelo',\n",
       " 'angels',\n",
       " 'anger',\n",
       " ...]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_Count_vect = pd.DataFrame(X_count_vect.toarray(), columns = X_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100m</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zoot</th>\n",
       "      <th>zorg</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  007  05  10  100  1000  100m  101  102   ...     zoom  zooming  \\\n",
       "0   0    0    0   0  10    0     0     0    0    0   ...        0        0   \n",
       "1   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "2   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "3   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "4   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "\n",
       "   zooms  zoot  zorg  zorro  zucker  zuko  zwick  zwigoff  \n",
       "0      0     0     0      0       0     0      0        0  \n",
       "1      0     0     0      0       0     0      0        0  \n",
       "2      0     0     0      0       0     0      0        0  \n",
       "3      0     0     0      0       0     0      0        0  \n",
       "4      0     0     0      0       0     0      0        0  \n",
       "\n",
       "[5 rows x 23784 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Count_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_Count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 23784)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Count_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Count_vect, y, test_size =0.25, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if error comes because of fit word as it is in bag of words too then perform the following\n",
    "X_Count_vect = X_Count_vect.rename(columns = {'fit':'fit_features'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 23784)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 23784)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    758\n",
       "0    742\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    258\n",
       "1    242\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_cv = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_clf_cv = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[213,  45],\n",
       "       [ 56, 186]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_clf_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = score_clf_cv[0][0]\n",
    "FP = score_clf_cv[0][1]\n",
    "FN = score_clf_cv[1][0]\n",
    "TN = score_clf_cv[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 213\n",
      "False positive: 45\n",
      "False Negative: 56\n",
      "True Negative: 186\n"
     ]
    }
   ],
   "source": [
    "print(\"True positive:\", TP)\n",
    "print(\"False positive:\", FP)\n",
    "print(\"False Negative:\", FN)\n",
    "print(\"True Negative:\", TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correctly identified: 399\n",
      "Wrongly identified: 101\n"
     ]
    }
   ],
   "source": [
    "print(\"correctly identified:\", TP+TN)\n",
    "print(\"Wrongly identified:\", FN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us check if our accuracy changes after applying tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vect = TfidfVectorizer(min_df= 2, lowercase = True, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TFIDF = tf_vect.fit_transform(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 23784)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TFIDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TFIDF_names = tf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '007',\n",
       " '05',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '100m',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '10th',\n",
       " '11',\n",
       " '110',\n",
       " '113',\n",
       " '115',\n",
       " '11th',\n",
       " '12',\n",
       " '126',\n",
       " '129',\n",
       " '13',\n",
       " '130',\n",
       " '132',\n",
       " '137',\n",
       " '13th',\n",
       " '14',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1500s',\n",
       " '155',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '161',\n",
       " '16mm',\n",
       " '16th',\n",
       " '16x9',\n",
       " '17',\n",
       " '175',\n",
       " '1773',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800s',\n",
       " '1839',\n",
       " '1869',\n",
       " '1871',\n",
       " '1888',\n",
       " '18th',\n",
       " '19',\n",
       " '1900',\n",
       " '1912',\n",
       " '1914',\n",
       " '1919',\n",
       " '1925',\n",
       " '1928',\n",
       " '1930',\n",
       " '1930s',\n",
       " '1932',\n",
       " '1933',\n",
       " '1935',\n",
       " '1937',\n",
       " '1938',\n",
       " '1939',\n",
       " '1940',\n",
       " '1940s',\n",
       " '1941',\n",
       " '1943',\n",
       " '1944',\n",
       " '1945',\n",
       " '1947',\n",
       " '1948',\n",
       " '1949',\n",
       " '1950',\n",
       " '1950s',\n",
       " '1953',\n",
       " '1954',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '1960',\n",
       " '1960s',\n",
       " '1961',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1998s',\n",
       " '1999',\n",
       " '19th',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2013',\n",
       " '2017',\n",
       " '2020',\n",
       " '2029',\n",
       " '2050',\n",
       " '2058',\n",
       " '20s',\n",
       " '20th',\n",
       " '21',\n",
       " '2176',\n",
       " '21st',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '2400',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '25th',\n",
       " '26',\n",
       " '26th',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2d',\n",
       " '2nd',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30th',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '35',\n",
       " '35mm',\n",
       " '36',\n",
       " '360',\n",
       " '37',\n",
       " '39',\n",
       " '3d',\n",
       " '3po',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '40s',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '47',\n",
       " '48',\n",
       " '48th',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '50s',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '571',\n",
       " '58',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '6000',\n",
       " '607',\n",
       " '60s',\n",
       " '61',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '666',\n",
       " '69',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '70mm',\n",
       " '70s',\n",
       " '73',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '80s',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '8mm',\n",
       " '8th',\n",
       " '90',\n",
       " '90210',\n",
       " '90s',\n",
       " '91',\n",
       " '911',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '999',\n",
       " '9mm',\n",
       " '_____',\n",
       " '______',\n",
       " '_and_',\n",
       " '_babe_',\n",
       " '_blade',\n",
       " '_brazil_',\n",
       " '_do_',\n",
       " '_does_',\n",
       " '_don',\n",
       " '_film',\n",
       " '_in',\n",
       " '_is_',\n",
       " '_last_',\n",
       " '_life',\n",
       " '_must_',\n",
       " '_not_',\n",
       " '_real_',\n",
       " '_really_',\n",
       " '_saturday_night_live_',\n",
       " '_saving',\n",
       " '_scream_',\n",
       " '_that_',\n",
       " '_the',\n",
       " '_the_',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaliyah',\n",
       " 'aardman',\n",
       " 'aaron',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandons',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdomen',\n",
       " 'abducted',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'aberration',\n",
       " 'abetted',\n",
       " 'abetting',\n",
       " 'abhorrent',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abo',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abolish',\n",
       " 'abolitionists',\n",
       " 'abominable',\n",
       " 'abomination',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abound',\n",
       " 'abounding',\n",
       " 'abounds',\n",
       " 'abraham',\n",
       " 'abrahams',\n",
       " 'abrams',\n",
       " 'abrasive',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absinthe',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolution',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorption',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abuzz',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abyss',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accentuate',\n",
       " 'accentuates',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accolades',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'accosted',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accounted',\n",
       " 'accounts',\n",
       " 'accumulated',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'acerbic',\n",
       " 'aces',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achiever',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'achingly',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'ack',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acme',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquit',\n",
       " 'acquits',\n",
       " 'acquittal',\n",
       " 'acquitted',\n",
       " 'acres',\n",
       " 'acrimonious',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actioner',\n",
       " 'actioners',\n",
       " 'actionfest',\n",
       " 'actions',\n",
       " 'activated',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actualization',\n",
       " 'actualizing',\n",
       " 'actually',\n",
       " 'acumen',\n",
       " 'acupuncture',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'ad',\n",
       " 'ad2am',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'add',\n",
       " 'addams',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'addled',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'addy',\n",
       " 'ade',\n",
       " 'adefarasin',\n",
       " 'adept',\n",
       " 'adeptly',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adheres',\n",
       " 'adjacent',\n",
       " 'adjani',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjoining',\n",
       " 'adjust',\n",
       " 'adjuster',\n",
       " 'adjusting',\n",
       " 'administration',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admires',\n",
       " 'admiring',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admittance',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admittingly',\n",
       " 'admonition',\n",
       " 'ado',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptive',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adores',\n",
       " 'adorned',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrian',\n",
       " 'adrien',\n",
       " 'adrift',\n",
       " 'adroitly',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventurer',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adversarial',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertiser',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advisable',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advisers',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'aerial',\n",
       " 'aerosmith',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'afar',\n",
       " 'affability',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affectations',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affections',\n",
       " 'affects',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affinity',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'affirming',\n",
       " 'affleck',\n",
       " 'afflicted',\n",
       " 'affliction',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affraid',\n",
       " 'affront',\n",
       " 'afi',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afield',\n",
       " 'afloat',\n",
       " 'afo',\n",
       " 'afoot',\n",
       " 'afore',\n",
       " 'aforementioned',\n",
       " 'aformentioned',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africans',\n",
       " 'afro',\n",
       " 'aftereffects',\n",
       " 'afterglow',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'agape',\n",
       " 'agatha',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'ageing',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggravating',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'agile',\n",
       " 'agility',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agonizingly',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'ah',\n",
       " 'ahabs',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahern',\n",
       " 'ahh',\n",
       " 'ahmed',\n",
       " 'aid',\n",
       " 'aidan',\n",
       " 'aide',\n",
       " 'aided',\n",
       " 'aiding',\n",
       " 'aids',\n",
       " 'aiello',\n",
       " 'ailing',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimee',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'aired',\n",
       " 'aires',\n",
       " 'airline',\n",
       " 'airliner',\n",
       " 'airlock',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airwaves',\n",
       " 'airwolf',\n",
       " 'airy',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'aka',\n",
       " 'aki',\n",
       " 'akin',\n",
       " 'akira',\n",
       " 'akiva',\n",
       " 'akroyd',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'aladdin',\n",
       " 'alain',\n",
       " 'alan',\n",
       " 'alanis',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'albania',\n",
       " 'albanian',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albertson',\n",
       " 'albino',\n",
       " 'albinos',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alcoholics',\n",
       " 'alcoholism',\n",
       " 'alcott',\n",
       " 'alda',\n",
       " 'aldys',\n",
       " 'alec',\n",
       " 'alejandro',\n",
       " 'alek',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alessandro',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandra',\n",
       " 'alexandre',\n",
       " 'alfonso',\n",
       " 'alfre',\n",
       " 'alfred',\n",
       " 'algar',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'aliases',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alida',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienates',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'aliens',\n",
       " 'align',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alison',\n",
       " 'alive',\n",
       " 'allah',\n",
       " 'allan',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allegiances',\n",
       " 'allegory',\n",
       " 'allegra',\n",
       " 'allen',\n",
       " 'allergy',\n",
       " 'alleviate',\n",
       " 'alley',\n",
       " 'alleys',\n",
       " 'alliance',\n",
       " 'alliances',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'alligator',\n",
       " 'alligators',\n",
       " 'allison',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alluded',\n",
       " 'allure',\n",
       " 'alluring',\n",
       " 'allusion',\n",
       " 'allusions',\n",
       " 'ally',\n",
       " 'alma',\n",
       " 'almod',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alright',\n",
       " 'altar',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'alterations',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternates',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alters',\n",
       " 'althea',\n",
       " 'altman',\n",
       " 'altogether',\n",
       " 'altough',\n",
       " 'alum',\n",
       " 'alumni',\n",
       " 'alumnus',\n",
       " 'alvarado',\n",
       " 'alvin',\n",
       " 'alyson',\n",
       " 'alyssa',\n",
       " 'alzheimer',\n",
       " 'amadeus',\n",
       " 'amalgamation',\n",
       " 'amanda',\n",
       " 'amarillo',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurishly',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambassador',\n",
       " 'ambassadors',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'ambient',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambiguously',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambitiously',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'ambrose',\n",
       " 'ambulance',\n",
       " 'ambush',\n",
       " 'amc',\n",
       " 'amen',\n",
       " 'amendment',\n",
       " 'amends',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanized',\n",
       " 'americans',\n",
       " 'americas',\n",
       " 'ames',\n",
       " 'amiable',\n",
       " 'amicable',\n",
       " 'amid',\n",
       " 'amidala',\n",
       " 'amidst',\n",
       " 'amis',\n",
       " 'amish',\n",
       " 'amiss',\n",
       " 'amistad',\n",
       " 'ammo',\n",
       " 'ammunition',\n",
       " 'amnesia',\n",
       " 'amnesiac',\n",
       " 'amok',\n",
       " 'amon',\n",
       " 'amoral',\n",
       " 'amorality',\n",
       " 'amos',\n",
       " 'amounted',\n",
       " 'amounts',\n",
       " 'amphetamines',\n",
       " 'amphibian',\n",
       " 'ample',\n",
       " 'amplified',\n",
       " 'amply',\n",
       " 'amputated',\n",
       " 'amuck',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusements',\n",
       " 'amusing',\n",
       " 'amusingly',\n",
       " 'amy',\n",
       " 'anaconda',\n",
       " 'anacondas',\n",
       " 'anakin',\n",
       " 'anal',\n",
       " 'analogy',\n",
       " 'analyses',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analysts',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'analyzing',\n",
       " 'anand',\n",
       " 'anarchic',\n",
       " 'anarchists',\n",
       " 'anarchy',\n",
       " 'anastasia',\n",
       " 'anatomy',\n",
       " 'ancestors',\n",
       " 'anchor',\n",
       " 'anchors',\n",
       " 'ancient',\n",
       " 'anders',\n",
       " 'anderson',\n",
       " 'andersons',\n",
       " 'andie',\n",
       " 'andre',\n",
       " 'andrea',\n",
       " 'andreas',\n",
       " 'andrew',\n",
       " 'andrews',\n",
       " 'android',\n",
       " 'androids',\n",
       " 'andromeda',\n",
       " 'andrzej',\n",
       " 'andy',\n",
       " 'anecdotal',\n",
       " 'anecdote',\n",
       " 'anecdotes',\n",
       " 'anemic',\n",
       " 'anew',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelic',\n",
       " 'angelina',\n",
       " 'angelo',\n",
       " 'angels',\n",
       " 'anger',\n",
       " ...]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TFIDF_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tf = pd.DataFrame(X_TFIDF.toarray(), columns = X_TFIDF_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100m</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zoot</th>\n",
       "      <th>zorg</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  007   05        10  100  1000  100m  101  102   ...     zoom  \\\n",
       "0  0.0  0.0  0.0  0.0  0.396904  0.0   0.0   0.0  0.0  0.0   ...      0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  0.0  0.0   ...      0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  0.0  0.0   ...      0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  0.0  0.0   ...      0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.000000  0.0   0.0   0.0  0.0  0.0   ...      0.0   \n",
       "\n",
       "   zooming  zooms  zoot  zorg  zorro  zucker  zuko  zwick  zwigoff  \n",
       "0      0.0    0.0   0.0   0.0    0.0     0.0   0.0    0.0      0.0  \n",
       "1      0.0    0.0   0.0   0.0    0.0     0.0   0.0    0.0      0.0  \n",
       "2      0.0    0.0   0.0   0.0    0.0     0.0   0.0    0.0      0.0  \n",
       "3      0.0    0.0   0.0   0.0    0.0     0.0   0.0    0.0      0.0  \n",
       "4      0.0    0.0   0.0   0.0    0.0     0.0   0.0    0.0      0.0  \n",
       "\n",
       "[5 rows x 23784 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TF_train, X_TF_test, y_TF_train, y_TF_test = train_test_split(X_tf, y, test_size = 0.25, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 23784)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TF_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 23784)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TF_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_TF_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_TF_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_tf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tf.fit(X_TF_train, y_TF_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_TF_pred = clf_tf.predict(X_TF_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_TF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_TF_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_TF_test, y_TF_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_clf_tf = confusion_matrix(y_TF_test, y_TF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[211,  47],\n",
       "       [ 43, 199]], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_clf_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = score_clf_tf[0][0]\n",
    "FP =  score_clf_tf[0][1]\n",
    "FN = score_clf_tf[1][0]\n",
    "TN = score_clf_tf[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 211\n",
      "False positive: 47\n",
      "False Negative: 43\n",
      "True Negative: 199\n"
     ]
    }
   ],
   "source": [
    "print(\"True positive:\", TP)\n",
    "print(\"False positive:\", FP)\n",
    "print(\"False Negative:\", FN)\n",
    "print(\"True Negative:\", TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correctly identified: 410\n",
      "Wrongly identified: 90\n"
     ]
    }
   ],
   "source": [
    "print(\"correctly identified:\", TP+TN)\n",
    "print(\"Wrongly identified:\", FN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
